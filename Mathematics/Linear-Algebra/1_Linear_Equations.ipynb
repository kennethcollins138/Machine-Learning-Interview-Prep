{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Linear Equations and Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectors:** A vector is a way of representing a list of data. It can be used to establish relationships between points. In Python, you can think of a vector as a list.\n",
    "\n",
    "### Types of Vectors:\n",
    "- **Geometric Vectors:** These are the vectors you might be familiar with from physics. They are directed segments that can be represented graphically. You can add these vectors together to create a new vector.\n",
    "- **Polynomial Vectors:** You can think of polynomial vectors as vectors where each term of the polynomial represents a different element in the vector. For example, the polynomial 1 + x/2 + 3x^2 can be represented as the vector [1, 1/2, 3]. Polynomials can be added together to create new polynomials.\n",
    "- **Audio Signals:** Audio signals can be represented as vectors. The waveforms of audio signals are similar to sine and cosine functions. Fourier Transforms, which convert a function of time into a function of frequency, are a key concept in this area.\n",
    "- **Elements of R^n:** This is a more abstract concept. In an n-dimensional space, any point can be represented as a vector of n elements, where each element is a coordinate along one of the dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalars:\n",
    "Going back to the equation for a line. Notice in the format y = mx + b. You have your variable x, and your value m. Your scalar is your multiple which can be any real number! What this number does, it 'scales' the values within a matrix. Imagine in something like a vector like 3[1,2,3], we'd simply multiply each value by 3 to get [3,6,9]!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System of Linear Equations \n",
    "### What are they?  \n",
    "Imagine a list of equations such as ai1(x1) + ... + ain(xn). Now imagine a list of multiple equations such as:  \n",
    "x1 + 2x2 + x3 = 8  \n",
    "x1 + x2 = 2  \n",
    "x2 = 2  \n",
    "We can take these values and solve for them by doing simple algebra or we can take the coefficents  and vectors to form a matrix such as  \n",
    "[1 2 1] [x1]   [8]  \n",
    "[1 1 0] [x2] = [2]  \n",
    "[0 1 0] [x3]   [2]  \n",
    "\n",
    "Your equation is simply Ax = b where Matrix A:  \n",
    "1 2 1  \n",
    "1 1 0  \n",
    "0 1 0  \n",
    "\n",
    "Vector x:  \n",
    "x1  \n",
    "x2  \n",
    "x3  \n",
    "\n",
    "Vector b:  \n",
    "8  \n",
    "2  \n",
    "2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note\n",
    "Im going to jump right here for my own personal reasons, I'm going to leave resources that help break this down, but I personally dont need to stay on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Addition and Multiplication  \n",
    "\n",
    "**Addition:** Matrices can only be added if they have the same dimensions. For example, a matrix A(2x3) can only be added to a matrix B(2x3) because they have the same shape.\n",
    "\n",
    "**Multiplication:** Matrices can only be multiplied if the number of columns in the first matrix is equal to the number of rows in the second matrix. For example, if we have two matrices with dimensions (2x3) and (3x4), they can be multiplied in this order because the inner dimensions are both 3. However, they can't be multiplied in the reverse order (i.e., (3x4)(2x3)) because the inner dimensions aren't the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity Matrix\n",
    "\n",
    "An identity matrix is a special type of square matrix where all the elements of the principal (main) diagonal are ones and all other elements are zeros. For a 2x2 matrix, an identity matrix would look like this:  \n",
    "\n",
    "[1 0]  \n",
    "[0 1]  \n",
    "\n",
    "\n",
    "The identity matrix is important because it's the multiplicative identity in the world of matrices. This means that when any matrix is multiplied by an identity matrix, the original matrix is unchanged. Here's an example with a 2x2 matrix A:  \n",
    "\n",
    "Matrix A:  \n",
    "[a b]  \n",
    "[c d]  \n",
    "\n",
    "Identity Matrix I:  \n",
    "[1 0]  \n",
    "[0 1]  \n",
    "\n",
    "Multiplication of A and I (AI):  \n",
    "[a b]  \n",
    "[c d]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverses and Transposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix Inverse:**\n",
    "\n",
    "The inverse of a matrix A is denoted as A^-1. It is a unique matrix that when multiplied with A, results in the identity matrix I. In other words, AA^-1 = A^-1A = I. \n",
    "\n",
    "A matrix is said to be **invertible** or **nonsingular** if its inverse exists. This means that the matrix has full rank, i.e., all its rows (or columns) are linearly independent. \n",
    "\n",
    "On the other hand, a matrix is said to be **singular** or **noninvertible** if its inverse does not exist. This usually means that the matrix does not have full rank, i.e., it has linearly dependent rows (or columns).\n",
    "\n",
    "**Matrix Transpose:**\n",
    "\n",
    "The transpose of a matrix A is denoted as A^T. It is obtained by flipping the matrix over its diagonal. This swaps the row and column indices of each element. For example, if A is an m x n matrix, then A^T is an n x m matrix.\n",
    "\n",
    "**Regular Matrix:**\n",
    "\n",
    "A matrix is said to be **regular** if it is square (i.e., has the same number of rows and columns) and has an inverse. In other words, a regular matrix is a nonsingular square matrix.\n",
    "\n",
    "These concepts are fundamental in linear algebra and are widely used in various fields such as computer graphics, machine learning, and data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance of Inverses, Transposes, and Matrix Types\n",
    "\n",
    "**Matrix Inverse:**\n",
    "\n",
    "The inverse of a matrix is crucial in solving systems of linear equations. If a matrix A represents a system of linear equations, then its inverse A^-1 can be used to find the solution vector. This is because if Ax = b represents the system of equations, then multiplying both sides by A^-1 gives x = A^-1b, which is the solution.\n",
    "\n",
    "**Matrix Transpose:**\n",
    "\n",
    "The transpose of a matrix is important in many areas of mathematics and computer science. For example, in machine learning, the transpose of a matrix is often used in the calculation of the gradient for optimization algorithms. It's also used in operations like calculating the dot product of vectors.\n",
    "\n",
    "**Singular and Nonsingular Matrices:**\n",
    "\n",
    "The distinction between singular and nonsingular matrices is important because it determines whether a system of linear equations has a unique solution. Nonsingular (invertible) matrices correspond to systems with a unique solution, while singular (noninvertible) matrices correspond to systems with either no solutions or infinitely many solutions.\n",
    "\n",
    "**Regular Matrices:**\n",
    "\n",
    "Regular matrices are important because they are guaranteed to have an inverse. This makes them particularly useful in many mathematical operations where the inverse of a matrix is required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The determinant is a special number that can be calculated from a square matrix. It's denoted as det(A) or |A| for a matrix A.\n",
    "\n",
    "The determinant helps us find the inverse of a matrix, tells us things about the matrix that are useful in systems of linear equations, calculus and more.\n",
    "\n",
    "### Calculating Determinants:\n",
    "\n",
    "For a 2x2 matrix, the determinant can be calculated as follows:  \n",
    "\n",
    "|a b| = ad - bc|c d|\n",
    "\n",
    "\n",
    "For a 3x3 matrix, the determinant can be calculated as follows:\n",
    "\n",
    "If the matrix is:\n",
    "\n",
    "|a  b  c|\n",
    "|d  e  f|\n",
    "|g  h  i|\n",
    "\n",
    "Then the determinant is calculated as:\n",
    "\n",
    "det = aei + bfg + cdh - ceg - bdi - afh\n",
    "\n",
    "\n",
    "For larger matrices, the calculation is more complex and often involves recursion and the concept of a minor of a matrix.\n",
    "\n",
    "### Significance of Determinants:\n",
    "\n",
    "1. **Invertibility:** A matrix is invertible (or nonsingular) if and only if its determinant is non-zero. If the determinant is zero, the matrix is singular and does not have an inverse.\n",
    "\n",
    "2. **System of Equations:** The determinant can be used to determine whether a system of linear equations has a unique solution (determinant is non-zero), no solution, or infinitely many solutions (determinant is zero).\n",
    "\n",
    "3. **Volume:** In geometry, the absolute value of the determinant of a matrix can be used to calculate the volume of a parallelepiped defined by the column vectors of the matrix.\n",
    "\n",
    "4. **Eigenvalues:** Determinants are used in the calculation of eigenvalues, which are important in many areas of computer science and data science, including machine learning algorithms.\n",
    "\n",
    "### Intuition:\n",
    "The determinant can be conceptualized as the volume of a vector space. Specifically, the absolute value of the determinant of a matrix can be interpreted as the scaling factor by which the matrix transforms volumes in the vector space. \n",
    "\n",
    "For a 2D matrix, the determinant represents the area of the parallelogram spanned by the column vectors (or row vectors) of the matrix. For a 3D matrix, the determinant represents the volume of the parallelepiped spanned by the column vectors. In three dimensions, a matrix represents a linear transformation that can stretch, shrink, rotate, and skew the space. The determinant of a 3D matrix gives us a measure of how this transformation changes the volume in the space.\n",
    "\n",
    "Consider a 3x3 matrix where each column is a 3D vector. These vectors can be thought of as the edges of a parallelepiped (a 3D shape with six faces, each of which is a parallelogram). The determinant of this matrix is equal to the volume of this parallelepiped.\n",
    "\n",
    "To visualize this, imagine that the three vectors are the edges of a box originating from the origin of the space. The determinant of the matrix formed by these vectors will give the volume of this box.\n",
    "\n",
    "If the vectors that form a matrix are linearly dependent, then the matrix will have a determinant of zero. This is because linearly dependent vectors do not span the full space, and thus the \"volume\" they form, as represented by the determinant, is zero. This also means that the matrix is singular, or non-invertible.\n",
    "\n",
    "If the determinant is positive, the transformation preserves the orientation of the space. If it's negative, the transformation reverses the orientation. If the determinant is zero, the vectors lie on a line or a plane, meaning the volume of the parallelepiped is zero. This corresponds to the matrix being singular or non-invertible.\n",
    "\n",
    "If the determinant is zero, it means that the matrix collapses the volume to zero, which corresponds to the matrix's column vectors being linearly dependent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplication by a Scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalar multiplication involves multiplying a matrix by a scalar (a single number). Each entry in the matrix is multiplied by the scalar.\n",
    "\n",
    "For example, if we have a matrix A and a scalar c:   \n",
    "Matrix A:    \n",
    "|a b|   \n",
    "|c d|    \n",
    "scalar c times Matrix A:    \n",
    "|ca cb|    \n",
    "|cc cd|   \n",
    "\n",
    "\n",
    "### Properties of Scalar Multiplication:\n",
    "\n",
    "1. **Associativity:** For any scalar c and d, and any matrix A, we have (cd)A = c(dA). This means that the order in which the scalar multiplication is performed does not matter.\n",
    "\n",
    "2. **Distributivity over Matrix Addition:** For any scalars c and d, and any matrices A and B of the same size, we have c(A + B) = cA + cB. This means that multiplying a scalar with the sum of two matrices is the same as multiplying the scalar with each matrix separately and then adding the results.\n",
    "\n",
    "3. **Distributivity over Scalar Addition:** For any scalars c and d, and any matrix A, we have (c + d)A = cA + dA. This means that multiplying a matrix by the sum of two scalars is the same as multiplying the matrix by each scalar separately and then adding the results.\n",
    "\n",
    "4. **Multiplicative Identity:** For any matrix A, we have 1A = A. This means that multiplying any matrix by the scalar 1 does not change the matrix.\n",
    "\n",
    "### Intuition for Scalar Multiplication\n",
    "\n",
    "Scalar multiplication can be thought of as scaling or stretching the matrix. When you multiply a matrix by a scalar, you're essentially changing the scale of the matrix, but not its direction.\n",
    "\n",
    "1. **Associativity:** The property of associativity in scalar multiplication is like saying that it doesn't matter how you group your operations. Whether you multiply the scalars first and then multiply the result by the matrix, or you multiply one scalar by the matrix first and then multiply the result by the other scalar, you'll end up with the same result. It's like saying that if you want to scale an object in a video game, it doesn't matter if you scale the x and y dimensions first and then the z dimension, or if you scale the z dimension first and then the x and y dimensions.\n",
    "\n",
    "2. **Distributivity over Matrix Addition:** This property is like saying that if you have two objects and you want to scale them and then combine them, it's the same as if you combined them first and then scaled the result. This is intuitive if you think about combining objects as adding them together.\n",
    "\n",
    "3. **Distributivity over Scalar Addition:** This property is like saying that if you want to scale an object by two different amounts and then add the results, it's the same as if you added the scaling factors first and then scaled the object by the result. This is intuitive if you think about scaling as multiplying.\n",
    "\n",
    "4. **Multiplicative Identity:** This property is like saying that if you scale an object by 1, you're not changing anything. The object stays the same size. This is intuitive because multiplying by 1 doesn't change the value of a number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving systems of Linear Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A system of linear equations is a collection of one or more linear equations involving the same variables. For example:  \n",
    "a1x + b1y = c1 a2x + b2y = c2  \n",
    "\n",
    "\n",
    "A solution to the system is a set of values for the variables that makes all the equations true.\n",
    "\n",
    "**Methods for Solving Systems of Linear Equations:**\n",
    "\n",
    "1. **Substitution:** Solve one of the equations for one variable and then substitute this expression into the other equation.\n",
    "\n",
    "2. **Elimination:** Add or subtract the equations to eliminate one of the variables, making it possible to solve for the other variable.\n",
    "\n",
    "3. **Matrix Method:** Write the system of equations in matrix form (Ax = b), and then use Gaussian elimination or another method to solve for the vector x.\n",
    "\n",
    "### Particular and General Solution\n",
    "\n",
    "The **particular solution** refers to a specific solution to a system of linear equations. It's a set of specific values for the variables that satisfy all the equations in the system.\n",
    "\n",
    "The **general solution** refers to a complete set of all possible solutions to a system of linear equations. It often includes free variables, which can take on any value.\n",
    "\n",
    "### Elementary Transformations\n",
    "\n",
    "Elementary transformations are operations that can be performed on a matrix or a system of equations without changing the solution. They include:\n",
    "\n",
    "1. **Swapping two rows or columns.**\n",
    "2. **Multiplying a row or column by a non-zero scalar.**\n",
    "3. **Adding a multiple of one row or column to another row or column.**\n",
    "\n",
    "### Pivots\n",
    "\n",
    "In the context of solving systems of linear equations, a pivot is the first non-zero element in a row of a matrix. The pivot is used to eliminate all the non-zero elements below it in the same column, which simplifies the system of equations.\n",
    "\n",
    "### Basic and Free Variables\n",
    "\n",
    "In the context of systems of linear equations, variables are classified as either basic or free.\n",
    "\n",
    "**Basic variables** correspond to the columns of the matrix that contain a pivot after the matrix has been reduced to row echelon form.\n",
    "\n",
    "**Free variables** correspond to the columns that do not contain a pivot. They can take on any value, and they represent the parameters in the general solution to the system of equations.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "The process of solving a system of linear equations is like trying to find the intersection point(s) of several lines (in two dimensions) or planes (in three dimensions). Each equation represents a line or plane, and the solution to the system is the point or points where they all intersect.\n",
    "\n",
    "Pivots are like the \"anchors\" that we use to simplify the system of equations. They help us eliminate other variables and reduce the system to a simpler form.\n",
    "\n",
    "Basic and free variables can be thought of as the \"fixed\" and \"flexible\" parts of the solution. Basic variables are determined by the system of equations, while free variables can vary freely without affecting the validity of the solution.  \n",
    "\n",
    "### Signifigance\n",
    "\n",
    "**Basic variables** are significant because they are the variables that are solved directly from the equations. They are determined by the system of equations and are \"fixed\" in the sense that their values are set by the specific solutions to the equations.  \n",
    "\n",
    "**Free variables**, on the other hand, are not directly solved from the equations. They can take on any value without affecting the validity of the solution. This \"freedom\" allows for multiple solutions to a system of equations. Free variables represent the parameters in the general solution to the system of equations.  \n",
    "\n",
    "The number of free variables in a system of linear equations corresponds to the dimension of the solution space. For example, if a system of linear equations has one free variable, the solution space is a line. If it has two free variables, the solution space is a plane, and so on.  \n",
    "\n",
    "The **particular solution** to a system of linear equations is a specific set of values for the variables that satisfy all the equations in the system. It represents a single point in the solution space. The particular solution is significant because it provides a concrete example of a solution to the system of equations.  \n",
    "\n",
    "The **general solution** to a system of linear equations, on the other hand, represents all possible solutions to the system. It often includes free variables, which can take on any value. The general solution is significant because it provides a complete description of the solution space. It tells us not only about specific solutions but also about the structure of the solution space as a whole.  \n",
    "\n",
    "In many applications, we are interested in the general solution because it gives us a full picture of all possible outcomes. However, in some cases, we might be interested in a particular solution that meets certain additional criteria.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homogeneous Systems\n",
    "\n",
    "A system of linear equations is said to be homogeneous if all of the constant terms are zero. In other words, a homogeneous system has the form `Ax = 0`, where `A` is a matrix and `x` is a vector of variables.\n",
    "\n",
    "Homogeneous systems are significant for several reasons:\n",
    "\n",
    "1. **Trivial Solution:** Homogeneous systems always have at least one solution, known as the trivial solution, where all variables are zero (`x = 0`). This is because if you multiply any matrix by a zero vector, the result is a zero vector, which means the equation `Ax = 0` is satisfied.\n",
    "\n",
    "2. **Linear Independence:** Homogeneous systems are often used to test for linear independence of vectors. If the only solution to the system `Ax = 0` is the trivial solution, the vectors are linearly independent. If there are nontrivial solutions, the vectors are linearly dependent.\n",
    "\n",
    "3. **Basis and Dimension:** The solutions to a homogeneous system can form a basis for a vector space, and the number of free variables in the solution can tell us the dimension of this space.\n",
    "\n",
    "4. **Homogeneous Coordinates:** In computer graphics and projective geometry, homogeneous coordinates are used to represent points at infinity and to perform transformations such as translation, rotation, and scaling. These operations can be represented as homogeneous systems of linear equations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Minus One Trick\n",
    "\n",
    "The \"Minus One Trick\" is a technique often used in linear algebra when dealing with systems of linear equations. It's particularly useful when you're trying to solve a system of equations using elimination or substitution.\n",
    "\n",
    "The idea is simple: multiply an equation by -1 to change the signs of all terms in the equation. This can make it easier to add or subtract equations in the system to eliminate variables.\n",
    "\n",
    "For example, consider the following system of equations:  \n",
    "x + y = 3x - y = 1  \n",
    "\n",
    "If we multiply the second equation by -1, we get:  \n",
    "x + y = 3 -x + y = -1 \n",
    "\n",
    "\n",
    "Now, if we add the two equations together, the `x` terms cancel out, and we're left with `2y = 2`, which simplifies to `y = 1`. We can then substitute `y = 1` into either of the original equations to solve for `x`.\n",
    "\n",
    "The \"Minus One Trick\" is significant because it's a simple but powerful tool that can make it easier to solve systems of linear equations. It's a testament to the fact that sometimes, a small change in perspective can make a big difference in problem-solving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Calculation\n",
    "\n",
    "The inverse of a matrix is a fundamental concept in linear algebra. If `A` is a square matrix, an inverse `A^-1` exists if and only if `A` is nonsingular (i.e., its determinant is not zero). The inverse is defined such that when it is multiplied by `A`, it yields the identity matrix `I`:\n",
    "\n",
    "A*A^-1 = A^-1 * A = I\n",
    "\n",
    "\n",
    "The inverse of a matrix is important for several reasons:\n",
    "\n",
    "1. **Solving Systems of Equations:** If the inverse of a matrix `A` exists, we can solve the system of linear equations `Ax = b` by multiplying both sides by `A^-1`, which gives `x = A^-1 * b`. This provides a direct method for finding the solution vector `x`.\n",
    "\n",
    "2. **Understanding Linear Transformations:** In the context of linear transformations, the inverse of a matrix undoes the transformation represented by the original matrix. For example, if `A` represents a rotation, `A^-1` represents a rotation in the opposite direction.\n",
    "\n",
    "3. **Determining Nonsingularity:** The existence of an inverse indicates that a matrix is nonsingular. This can be useful in many mathematical and computational contexts, as singular matrices often lead to problems such as division by zero or ill-conditioned systems.\n",
    "\n",
    "Calculating the inverse of a matrix can be computationally intensive for large matrices, but many efficient algorithms have been developed for this purpose. \n",
    "\n",
    "### Gaussian Elimination\n",
    "\n",
    "Gaussian elimination is a method used to solve systems of linear equations. It involves three types of elementary row operations:\n",
    "\n",
    "1. **Swapping two rows.**\n",
    "2. **Multiplying a row by a non-zero scalar.**\n",
    "3. **Adding a multiple of one row to another row.**\n",
    "\n",
    "The goal of Gaussian elimination is to transform the system's augmented matrix (the matrix that includes the coefficients and the constants from the right side of the equations) into an upper triangular matrix, where all the entries below the main diagonal are zero. This form is called row echelon form.\n",
    "\n",
    "Here's a step-by-step process of Gaussian elimination:\n",
    "\n",
    "1. **Pivot Selection:** Select a non-zero element in the first column (the pivot). If the first element of the first row is zero, swap this row with another one to get a non-zero pivot.\n",
    "\n",
    "2. **Elimination:** Use row operations to get zeros below the pivot.\n",
    "\n",
    "3. **Repeat:** Treat the remaining submatrix (ignoring the first row and column) as a new system and repeat the process.\n",
    "\n",
    "4. **Back Substitution:** Once the matrix is in row echelon form, start from the bottom and solve each equation one at a time. Substitute the known values into the other equations to find the remaining variables.\n",
    "\n",
    "### Gaussian Elimination and Determinants\n",
    "\n",
    "Gaussian elimination plays a crucial role in computing determinants for several reasons:\n",
    "\n",
    "1. **Simplification:** Gaussian elimination transforms a matrix into an upper triangular matrix (or row echelon form). The determinant of an upper triangular matrix is simply the product of the diagonal elements. This greatly simplifies the computation of the determinant, especially for large matrices.\n",
    "\n",
    "2. **Efficiency:** The process of Gaussian elimination is more efficient than the direct computation of determinants using cofactor expansion, especially for large matrices. Cofactor expansion has a time complexity of O(n!), while Gaussian elimination has a time complexity of O(n^3).\n",
    "\n",
    "3. **Stability:** Gaussian elimination is a numerically stable method for computing determinants. It avoids the accumulation of rounding errors that can occur with other methods, such as cofactor expansion.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
