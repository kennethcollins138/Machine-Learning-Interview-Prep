{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- most algorithms machine learning optimize an objective function with respect to a set of parameters\n",
    "- We can think of finding good parameters as an optimization problem\n",
    "\n",
    "## Functions and Domains\n",
    "\n",
    "- **Domain**: The domain of a function is the set of all possible inputs that the function can accept. \n",
    "\n",
    "    For example, consider a function `f(x) = sqrt(x)`. The square root of a number is only defined for non-negative numbers. Therefore, the domain of this function is all non-negative real numbers.\n",
    "\n",
    "- **Codomain**: The codomain of a function is the set that contains all potential outputs of the function. However, not all elements of the codomain need to be actual outputs. \n",
    "\n",
    "    For example, in the function `f(x) = x^2`, the codomain is all real numbers, because a square of a real number can be any real number. However, the actual outputs (the image or range) are only non-negative real numbers, because squaring a real number can never result in a negative number.\n",
    "\n",
    "- **Image**: The image of a function, also known as the range, is the set of all actual outputs of the function. \n",
    "\n",
    "    For example, in the function `f(x) = x^2`, the image is all non-negative real numbers, because squaring a real number can never result in a negative number.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiation of Univariate Functions\n",
    "\n",
    "- **Difference Quotient**: The difference quotient of a function `f(x)` is defined as `(f(x + h) - f(x)) / h`, where `h` is a small number. \n",
    "\n",
    "    The difference quotient gives the average rate of change of the function over the interval `[x, x + h]`. As `h` approaches 0, the difference quotient approaches the exact rate of change of the function at the point `x`, which is the derivative of the function at `x`.  \n",
    "\n",
    "    The difference quotient is a fundamental concept in calculus and it provides a way to approximate the slope of a function at a particular point, which is essentially what a derivative is.  \n",
    "\n",
    "    The intuition behind the difference quotient is that it calculates the average rate of change of a function over a small interval. This is like finding the slope of a secant line that passes through two points on the function: `(x, f(x))` and `(x + h, f(x + h))`.  \n",
    "\n",
    "    As `h` gets smaller and smaller, the second point gets closer and closer to `(x, f(x))`, and the secant line becomes a tangent line at `(x, f(x))`. The slope of this tangent line is the derivative of the function at `x`, which gives the instantaneous rate of change of the function at `x`.  \n",
    "\n",
    "    This is important because the derivative at a point can tell us a lot about the behavior of the function at that point. For example, if the derivative is positive, the function is increasing at that point. If the derivative is negative, the function is decreasing. If the derivative is zero, the function has a local maximum or minimum at that point. This information is crucial in many areas of science and engineering, including physics, economics, and machine learning.\n",
    "\n",
    "### Derivatives as Limits\n",
    "\n",
    "The derivative of a function at a point is defined as the limit of the difference quotient as `h` approaches 0. This is formally written as:\n",
    "\n",
    "`f'(x) = lim(h->0) [(f(x + h) - f(x)) / h]`\n",
    "\n",
    "This definition captures the idea of the instantaneous rate of change of the function at the point `x`, which is the slope of the tangent line to the function at `x`.\n",
    "\n",
    "Derivatives are important for several reasons:\n",
    "\n",
    "1. **Understanding Function Behavior**: Derivatives can tell us a lot about the behavior of a function. Positive derivatives indicate increasing functions, negative derivatives indicate decreasing functions, and a derivative of zero can indicate local maxima or minima.\n",
    "\n",
    "2. **Optimization**: We need to optimize a function (find its maximum or minimum). The derivative helps us find these maxima or minima, which is crucial in fields like machine learning, physics, and economics.\n",
    "\n",
    "3. **Modeling Change**: Derivatives are used to model rates of change in real-world phenomena. For example, in physics, the velocity of an object is the derivative of its position with respect to time, and the acceleration is the derivative of velocity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taylor Series\n",
    "\n",
    "- **Taylor Series**: The Taylor series of a function is an infinite series that represents the function as a sum of terms calculated from the function's derivatives at a single point.\n",
    "\n",
    "    The Taylor series of a function `f(x)` about the point `a` is given by:\n",
    "\n",
    "    `f(x) = f(a) + f'(a)(x - a) + f''(a)(x - a)^2 / 2! + f'''(a)(x - a)^3 / 3! + ...`\n",
    "\n",
    "    Each term in the series involves a higher order derivative of the function. The `(x - a)^n / n!` part is the general term of the series, where `n` is the order of the derivative.\n",
    "\n",
    "    The intuition behind the Taylor series is that it provides a way to approximate complex functions with simpler ones (polynomials). The more terms you include in the series, the better the approximation. In fact, if you include an infinite number of terms, the Taylor series becomes the function itself.\n",
    "\n",
    "- **Taylor Polynomials**: A Taylor polynomial is a polynomial that approximates a function by using information from the function's derivatives at a single point. It's essentially a finite portion of the Taylor series.\n",
    "\n",
    "    The nth degree Taylor polynomial of a function `f(x)` about the point `a` is given by:\n",
    "\n",
    "    `P_n(x) = f(a) + f'(a)(x - a) + f''(a)(x - a)^2 / 2! + ... + f^n(a)(x - a)^n / n!`\n",
    "\n",
    "    The intuition behind Taylor polynomials is similar to that of the Taylor series. They provide a way to approximate complex functions with simpler ones (polynomials). However, unlike the Taylor series, which is an infinite series, a Taylor polynomial has a finite number of terms. In other words, Higher order taylor polynomials approximate the function f better and more globally.\n",
    "\n",
    "    Taylor polynomials are important because they provide a more computationally feasible way to approximate functions compared to the full Taylor series, especially when only a certain degree of accuracy is needed.\n",
    "\n",
    "\n",
    "### Maclaurin Series and Analytic Functions\n",
    "\n",
    "- **Maclaurin Series**: A Maclaurin series is a special case of the Taylor series where the series is expanded about the point `a = 0`. The Maclaurin series of a function `f(x)` is given by:\n",
    "\n",
    "    `f(x) = f(0) + f'(0)x + f''(0)x^2 / 2! + f'''(0)x^3 / 3! + ...`\n",
    "\n",
    "- **Relation to Analytic Functions**: A function is said to be analytic at a point if it can be represented by a convergent power series in a neighborhood of that point. In other words, if a function can be expressed as a Taylor series (or a Maclaurin series, which is a special case of a Taylor series), then it is analytic at the point about which the series is expanded. This is important because analytic functions have many nice properties, such as being infinitely differentiable and having a Taylor series that converges to the function itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiation Rules\n",
    "\n",
    "1. **Constant Rule**: The derivative of a constant is zero. This is because a constant doesn't change, so its rate of change is zero.\n",
    "\n",
    "    `d/dx[c] = 0`\n",
    "\n",
    "2. **Power Rule**: The derivative of `x^n` is `n*x^(n-1)`. This rule comes from the limit definition of the derivative and binomial theorem.\n",
    "\n",
    "    `d/dx[x^n] = n*x^(n-1)`\n",
    "\n",
    "3. **Sum Rule**: The derivative of a sum of functions is the sum of their derivatives. This is intuitive because the rate of change of a sum of functions at a point is just the sum of their rates of change at that point.\n",
    "\n",
    "    `d/dx[f(x) + g(x)] = f'(x) + g'(x)`\n",
    "\n",
    "4. **Product Rule**: The derivative of a product of two functions is the first function times the derivative of the second, plus the second function times the derivative of the first. This rule is less intuitive and usually requires proof via the limit definition of the derivative.\n",
    "\n",
    "    `d/dx[f(x) * g(x)] = f(x)g'(x) + g(x)f'(x)`\n",
    "\n",
    "5. **Chain Rule**: The derivative of a composition of functions is the derivative of the outer function evaluated at the inner function, times the derivative of the inner function. This rule is crucial for differentiating complex functions and comes from the limit definition of the derivative.\n",
    "\n",
    "    `d/dx[f(g(x))] = f'(g(x)) * g'(x)`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
