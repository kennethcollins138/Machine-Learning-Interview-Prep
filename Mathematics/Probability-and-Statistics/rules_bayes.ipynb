{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum Rule, Product Rule, Bayes Theorem\n",
    "\n",
    "- Remember if A and B are two events, then the probability of A or B is given by the sum rule as follows:\n",
    "  - P(A or B) = P(A) + P(B) - P(A and B)\n",
    "- If A and B are independent events, then the probability of A and B is given by the product rule as follows:\n",
    "    - P(A and B) = P(A) * P(B)\n",
    "- Bayes Theorem is a way to find the probability of a cause given an effect. It is given by:\n",
    "    - P(A|B) = P(B|A) * P(A) / P(B)\n",
    "- Remember P(x,y) is the join distribution of the two random variables. P(x) is the marginal distribution of x which means the probability of x. P(x|y) is the conditional distribution of x given y which means the probability of x given y.\n",
    "- If y is descrete, its probability distribution is given by P(y) = sum(P(x,y)) for all x. If y is continuous, its probability distribution is given by P(y) = integral(P(x,y)) for all x.\n",
    "- When we sum or intergrate out the set of states y of the the random variable Y, we get the sum rule which is known as the marginalization rule. \n",
    "- The sum rule relates the joint distribution to a marginal distribution. The product rule relates the joint distribution to a conditional distribution. Bayes Theorem relates the conditional distribution to the joint distribution.\n",
    "- Typically the sum rule is computationally heavy since there is technically no end as it requires summing over all possible states of the random variable. The product rule is computationally heavy as well since it requires multiplying the probabilities of all possible states of the random variable. Bayes Theorem is computationally heavy as well since it requires multiplying the probabilities of all possible states of the random variable.\n",
    "\n",
    "### Prior Probability (Prior)\n",
    "\n",
    "- the prior probability is your belief about the probability of an event before you have seen any data. It's based on your existing knowledge or assumptions about the event.\n",
    "\n",
    "- **Intuition**: You can think of the prior as your initial guess or hypothesis about the probability of an event. For example, if you're trying to estimate the probability of a coin landing heads, and you have no reason to believe the coin is biased, you might start with a prior probability of 0.5 for heads.\n",
    "\n",
    "- **Example**: Suppose you're trying to estimate the proportion of left-handed people in the world. Before collecting any data, you might assume that the proportion is 0.1 (based on general knowledge that about 10% of people are left-handed). This is your prior. As you collect more data, you update this prior to form a more accurate estimate.\n",
    "\n",
    "### Likelihood\n",
    "\n",
    "- In statistics, the likelihood of a set of parameter values, given some observed outcomes, is equal to the probability of those observed outcomes given those parameter values. It's a measure of how well the observed outcomes are predicted by the parameter values.\n",
    "\n",
    "- **Intuition**: You can think of the likelihood as a way to measure how well a particular set of parameter values explains the data you've observed. The higher the likelihood, the better the parameter values explain the data.\n",
    "\n",
    "- **Example**: Suppose you're trying to estimate the probability of a coin landing heads (p), and you've observed 6 heads in 10 flips. The likelihood of p given these observations is the probability of getting 6 heads in 10 flips given p. If p=0.5, this likelihood would be calculated using the binomial distribution.\n",
    "\n",
    "### Posterior Probability (Posterior)\n",
    "\n",
    "- the posterior probability is the updated probability of an event occurring after taking into account the observed data. It's calculated using Bayes' theorem, which combines the prior probability and the likelihood of the observed data.\n",
    "\n",
    "- **Intuition**: You can think of the posterior as your updated belief about the probability of an event after seeing the data. It's a way to revise your initial guess (the prior) based on new information (the data).\n",
    "\n",
    "- **Example**: Continuing the example of estimating the proportion of left-handed people in the world, after collecting data and finding that 15 out of 100 people sampled are left-handed, you would update your prior   (0.1) to a posterior probability that takes this new data into account.\n",
    "\n",
    "## Marginal Likelihood\n",
    "\n",
    "- the marginal likelihood (also known as the evidence) is the probability of the observed data averaged over all possible values of the parameters. It's used as a normalization constant in Bayes' theorem.\n",
    "\n",
    "- **Intuition**: You can think of the marginal likelihood as a way to measure how well the model predicts the data, averaged over all parameter values. It's often used for model comparison: a model with a higher marginal likelihood is generally considered to better fit the data.\n",
    "\n",
    "- **Example**: Suppose you have two models for predicting the weather: one that uses only the current temperature, and one that uses both the current temperature and humidity. You could calculate the marginal likelihood for each model (i.e., the probability of the observed weather data given the model, averaged over all possible parameter values) to decide which model better fits the data.\n",
    "\n",
    "### Equation for Marginal Likelihood\n",
    "\n",
    "The marginal likelihood is calculated by integrating the product of the likelihood and the prior over all possible parameter values. In mathematical terms, if `θ` represents the parameters, `D` represents the data, `L(θ; D)` is the likelihood, and `p(θ)` is the prior, then the marginal likelihood `p(D)` is given by:\n",
    "\n",
    "∫ L(θ; D) * p(θ) dθ\n",
    "\n",
    "This equation says that to get the marginal likelihood, you multiply the likelihood by the prior for each possible value of the parameters, and then sum (or integrate) over all these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics\n",
    "\n",
    "## Means and Covariances\n",
    "\n",
    "- Mean and covariance are useful when describing probability distributions (expected values and spread)\n",
    "\n",
    "- **Mean**: The mean of a random variable is a measure of the central tendency of its distribution. It's the average value of the variable, and is calculated by summing all possible values of the variable, each weighted by its probability.\n",
    "\n",
    "- **Covariance**: The covariance between two random variables is a measure of how much they change together. It's calculated by summing the product of the differences of each variable from its mean, each weighted by the probability of their joint occurrence.\n",
    "\n",
    "- **Intuition**: You can think of the mean as the \"balance point\" of the distribution, and the covariance as a measure of how the variables change together. For example, if the covariance between two variables is positive, it means that when one variable is above its mean, the other variable tends to be above its mean as well.\n",
    "\n",
    "### Expected Value\n",
    "\n",
    "- **Expected Value**: The expected value of a random variable is a weighted average of all possible values that this random variable can take on. The weights are the probabilities of these outcomes.\n",
    "\n",
    "- **Intuition**: You can think of the expected value as the long-term average of repetitions of the same experiment it represents. For example, the expected value in rolling a six-sided die is 3.5, because, in the long run, after many rolls of the die, the average outcome is 3.5.\n",
    "\n",
    "- **Example**: Suppose you play a game where you win $5 if you roll a 6 on a fair six-sided die, and lose $1 otherwise. The expected value of this game can be calculated by multiplying each outcome by its probability and summing these products. In this case, the expected value is (1/6)*$5 + (5/6)*-$1 = -$0.17. This means that on average, you would expect to lose 17 cents each time you play this game.\n",
    "\n",
    "#### Expected Value for a Continuous Random Variable\n",
    "\n",
    "If `X` is a continuous random variable with probability density function `f(x)`, the expected value `E[X]` is given by:\n",
    "\n",
    "∫ x * f(x) dx (integrated over the entire range of X)\n",
    "\n",
    "This equation says that to get the expected value, you multiply each possible value of `X` by its probability density, and then integrate over all these values.\n",
    "\n",
    "#### Expected Value for a Discrete Random Variable\n",
    "\n",
    "If `X` is a discrete random variable that takes on the values `x1, x2, ..., xn` with corresponding probabilities `p1, p2, ..., pn`, the expected value `E[X]` is given by:\n",
    "\n",
    "E[X] = x1*p1 + x2*p2 + ... + xn*pn\n",
    "\n",
    "This equation says that to get the expected value, you multiply each possible value of `X` by its probability, and then sum these products.\n",
    "\n",
    "### Variance\n",
    "\n",
    "- **Variance**: Variance is a statistical measurement that describes the spread of data points in a data set around the mean. It is a measure of how far each number in the set is from the mean and thus from every other number in the set. It's often denoted as σ².\n",
    "\n",
    "- **Intuition**: Variance gives you a measure of how spread out the data is. It represents the variability from an average. High variance indicates that data points are spread out widely from the mean and from each other, while low variance indicates the opposite.\n",
    "\n",
    "### Covariance and Standard Deviation\n",
    "\n",
    "- **Covariance**: Covariance is a measure of how much two random variables vary together. A positive covariance means that the variables tend to show similar behavior - they increase or decrease together. A negative covariance means the variables show inverse behavior - one increases when the other decreases. For example, if you have two variables, age and income, a positive covariance would indicate that as age increases, income also tends to increase.\n",
    "\n",
    "- **Standard Deviation**: Standard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean of the set, while a high standard deviation indicates that the values are spread out over a wider range. Standard deviation can be thought of as a measure of uncertainty. In a set of data, a high standard deviation means the data points are more spread out, indicating a higher level of uncertainty. For example, if you have a set of test scores with a high standard deviation, this would indicate that students had a wide range of scores.\n",
    "\n",
    "#### Importance of Covariance and Standard Deviation in Machine Learning\n",
    "\n",
    "- **Covariance**: Understanding the covariance between different features in your dataset can help you to understand the relationships between these features. This can be useful for feature selection and engineering. For example, if two features have a high covariance, they are highly correlated and may provide redundant information, so you might choose to drop one of them. Covariance is also used in algorithms like Principal Component Analysis (PCA) to reduce the dimensionality of the data.\n",
    "\n",
    "- **Standard Deviation**: Standard deviation is a measure of data variability. In machine learning, it's important to understand this variability as it can influence the performance of your model. For example, features with a high standard deviation might dominate the learning process in certain models, leading to suboptimal performance. This is why it's common to scale features to have zero mean and unit variance. Standard deviation is also used to understand the spread of errors or predictions made by the model.\n",
    "\n",
    "#### Empirical Mean and Covariance\n",
    "\n",
    "The empirical mean and empirical covariance are estimates of the mean and covariance based on observed data. They are called \"empirical\" because they are derived from empirical observations, rather than from a theoretical distribution.\n",
    "\n",
    "- **Empirical Mean**: This is simply the average of the observed data. It provides an estimate of the central location of the data. If the data is drawn from a distribution with a true mean μ, the empirical mean will tend to be close to μ if the number of observations is large (according to the law of large numbers).\n",
    "\n",
    "- **Empirical Covariance**: This is an estimate of the covariance matrix of the observed data. It provides an estimate of how different variables in the data vary together. If the data is drawn from a distribution with a true covariance matrix Σ, the empirical covariance matrix will tend to be close to Σ if the number of observations is large.\n",
    "\n",
    "Compared to the \"regular\" (i.e., true or theoretical) mean and covariance, the empirical mean and covariance are estimates based on actual data. They provide a way to estimate the true parameters when these are unknown. However, they are subject to sampling error, especially when the number of observations is small.\n",
    "\n",
    "- **Example**: If you have a group of values 2, 4, 6, the mean is 4, and the variance is 4. This is because the differences from the mean are 2 and -2, their squares are 4 and 4, and their average is 4.\n",
    "\n",
    "### Correlation\n",
    "\n",
    "- **Correlation**: Correlation is a statistical measure that describes the degree to which two variables move in relation to each other. It's often denoted by the symbol `r` and ranges between -1 and 1.\n",
    "\n",
    "- **Intuition**: If the correlation is positive, it means that as one variable increases, the other also increases, and vice versa. If the correlation is negative, it means that as one variable increases, the other decreases. If the correlation is zero, it means that there is no linear relationship between the variables.\n",
    "\n",
    "- **Example**: If you have two variables, height and weight, a positive correlation might indicate that as height increases, weight also tends to increase.\n",
    "\n",
    "#### Correlation as Normalized Covariance\n",
    "\n",
    "Correlation is essentially a normalized version of covariance that provides an interpretable score by scaling the values between -1 and 1. \n",
    "\n",
    "Covariance measures how two variables vary together, but its magnitude is unbounded and depends on the units of measurement of the variables. This makes it difficult to interpret, especially when comparing covariances between different pairs of variables.\n",
    "\n",
    "Correlation, on the other hand, is a standardized form of covariance that is dimensionless and always falls between -1 (perfect negative correlation) and 1 (perfect positive correlation). It provides a measure of the strength and direction of the linear relationship between two variables.\n",
    "\n",
    "The correlation between two variables X and Y can be calculated from the covariance as follows:\n",
    "\n",
    "Correlation(X, Y) = Covariance(X, Y) / (StandardDeviation(X) * StandardDeviation(Y))\n",
    "\n",
    "This formula shows that correlation is the covariance of two variables divided by the product of their standard deviations. This normalization process allows correlation to provide a more interpretable and standardized measure of the relationship between two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of Mean and Covariance under Affine Transformations\n",
    "\n",
    "Affine transformations of a random variable involve operations of scaling (multiplication by a constant), translation (addition of a constant), or both. The properties of mean and covariance under affine transformations are particularly useful in statistics and data analysis.\n",
    "\n",
    "Let's consider a random variable X with mean μ and variance σ². Let Y = aX + b be an affine transformation of X, where a and b are constants. The following properties hold:\n",
    "\n",
    "- **Mean**: The mean of Y is given by E[Y] = aE[X] + b = aμ + b. This means that the mean of an affine transformation of a random variable is the affine transformation of the mean.\n",
    "\n",
    "- **Variance**: The variance of Y is given by Var[Y] = a²Var[X] = a²σ². This means that the variance of an affine transformation of a random variable is the square of the scaling factor times the original variance. Note that the variance does not depend on the translation (b).\n",
    "\n",
    "- **Covariance**: If Z = cX + d is another affine transformation of X, the covariance of Y and Z is given by Cov[Y,Z] = a*c*Cov[X,X] = a*c*σ². This means that the covariance of two affine transformations of a random variable is the product of the scaling factors times the original variance.\n",
    "\n",
    "These properties are useful because they allow us to understand how the mean, variance, and covariance of a random variable change under affine transformations. This is particularly important in many areas of data analysis where such transformations are common, such as in linear regression, Principal Component Analysis (PCA), and data normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Independence\n",
    "\n",
    "- **Statistical Independence**: Two random variables are said to be statistically independent if the occurrence of one does not affect the probability of the occurrence of the other. In other words, the events are unrelated.\n",
    "\n",
    "- **Intuition**: If two variables are independent, knowing the outcome of one variable doesn't give any information about the outcome of the other variable. For example, if you flip a coin twice, the outcome of the first flip doesn't affect the outcome of the second flip. These events are independent.\n",
    "\n",
    "- **Mathematically**: Two random variables X and Y are independent if and only if their joint probability distribution is the product of their marginal probability distributions. That is, P(X and Y) = P(X)P(Y) for all values of X and Y.\n",
    "\n",
    "- **Covariance and Independence**: If two variables are independent, their covariance is zero. However, the reverse is not necessarily true. Zero covariance between two variables does not imply independence, unless the variables are normally distributed.\n",
    "\n",
    "### Independent and Identically Distributed (i.i.d.) Random Variables\n",
    "\n",
    "When models or data points are labeled as independent and identically distributed (often abbreviated as i.i.d.), it means that each data point in the model:\n",
    "\n",
    "1. **Independence**: Does not depend on any other data points. In other words, knowing the outcome of one data point does not provide any information about the outcome of another data point.\n",
    "\n",
    "2. **Identically Distributed**: All data points follow the same probability distribution. This means that they all have the same mean, variance, and other statistical properties.\n",
    "\n",
    "The assumption of i.i.d. is often made in statistical and machine learning models because it greatly simplifies the analysis and the computations involved. For example, in linear regression, the residuals (errors) are often assumed to be i.i.d.\n",
    "\n",
    "It's important to note that this is an idealized assumption and may not hold in real-world data. For example, in time series data, observations are often dependent on previous observations, violating the independence assumption.\n",
    "\n",
    "### Conditional Independence\n",
    "\n",
    "- **Conditional Independence**: Two random variables X and Y are said to be conditionally independent given a third variable Z if the occurrence of X does not affect the probability of Y given that Z is known, and vice versa.\n",
    "\n",
    "- **Intuition**: If two variables are conditionally independent given a third variable, knowing the outcome of one variable doesn't give any additional information about the outcome of the other variable once we know the value of the third variable. \n",
    "\n",
    "- **Mathematically**: Two random variables X and Y are conditionally independent given a random variable Z if and only if the conditional joint probability distribution of X and Y given Z is the product of the conditional marginal probability distributions of X and Y given Z. That is, P(X and Y | Z) = P(X | Z)P(Y | Z) for all values of X, Y, and Z.\n",
    "\n",
    "- **Covariance and Conditional Independence**: If two variables are conditionally independent given a third variable, their conditional covariance given the third variable is zero. However, the reverse is not necessarily true. Zero conditional covariance between two variables given a third variable does not imply conditional independence."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
