{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manhattan Norm and Distance\n",
    "\n",
    "The Manhattan norm (also known as the L1 norm or taxicab norm) and Manhattan distance (also known as city block distance) are measures of distance in a vector space.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "The Manhattan norm of a vector is the sum of the absolute values of its components. It gets its name from the grid layout of streets in Manhattan, which resembles a coordinate system. If you were to travel from one point to another in Manhattan, you would have to move along the grid lines (streets), so the distance you would travel (the Manhattan distance) is the sum of the horizontal and vertical distances.\n",
    "\n",
    "### Computation\n",
    "\n",
    "\n",
    "The Manhattan norm of a vector `x` in n-dimensional real or complex space is computed as:\n",
    "\n",
    "||x||1 = |x1| + |x2| + ... + |xn|\n",
    "\n",
    "\n",
    "The Manhattan distance between two points `x` and `y` is the Manhattan norm of the difference between the points:\n",
    "\n",
    "d(x, y) = ||x - y||1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Norm and Distance\n",
    "\n",
    "The Euclidean norm (also known as the L2 norm or 2-norm) and Euclidean distance are measures of distance in a vector space.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "The Euclidean norm of a vector is the length of the vector from the origin to the point represented by the vector. It's the straight-line distance, or \"as the crow flies\" distance. \n",
    "\n",
    "The Euclidean distance between two points is the length of the straight line between them. It's like the distance measured with a ruler between two points on a map.\n",
    "\n",
    "### Computation\n",
    "\n",
    "The Euclidean norm of a vector `x` in n-dimensional real or complex space is computed as:\n",
    "\n",
    "||x||2 = sqrt(x1^2 + x2^2 + ... + xn^2)\n",
    "\n",
    "\n",
    "The Euclidean distance between two points `x` and `y` is the Euclidean norm of the difference between the points:\n",
    "\n",
    "d(x, y) = ||x - y||2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chebyshev Distance\n",
    "\n",
    "Chebyshev distance (also known as maximum value distance) is a metric defined on a vector space where the distance between two vectors is the greatest of their differences along any coordinate dimension.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "Imagine you're moving on a grid and you can move in 8 directions: horizontally, vertically, and diagonally. The Chebyshev distance between two points is the minimum number of moves you need to reach one point from the other. It's named after Pafnuty Chebyshev, a Russian mathematician.\n",
    "\n",
    "### Computation\n",
    "\n",
    "The Chebyshev distance between two points `x` and `y` in n-dimensional space is computed as:\n",
    "\n",
    "d(x, y) = max(|x1 - y1|, |x2 - y2|, ..., |xn - yn|)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minkowski Distance\n",
    "\n",
    "Minkowski distance is a metric in a normed vector space which can be considered as a generalization of both Euclidean distance and Manhattan distance.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "The Minkowski distance between two variables is a generalized metric form of Euclidean distance and Manhattan distance. It's named after the German mathematician Hermann Minkowski.\n",
    "\n",
    "### Computation\n",
    "\n",
    "The Minkowski distance of order `p` between two points `x` and `y` in n-dimensional real space is defined as:\n",
    "\n",
    "d(x, y) = (sum(|xi - yi|^p))^(1/p) for i = 1 to n\n",
    "\n",
    "\n",
    "When `p=1`, the Minkowski distance equals the Manhattan distance. When `p=2`, it equals the Euclidean distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming Distance\n",
    "\n",
    "Hamming distance is a metric used to measure the difference between two strings of equal length. It's named after Richard Hamming, an American mathematician and computer scientist.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "The Hamming distance between two strings is the number of positions at which the corresponding symbols are different. It measures the minimum number of substitutions required to change one string into the other.\n",
    "\n",
    "### Computation\n",
    "\n",
    "The Hamming distance between two strings `s` and `t` of equal length is defined as:\n",
    "\n",
    "d(s, t) = sum(s[i] != t[i]) for i = 1 to n\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space. It's often used to compare documents in text analysis.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "The cosine similarity captures the angle between the two vectors. It's a judgement of orientation rather than magnitude. If the vectors are orthogonal (the angle between them is 90 degrees), they are less similar. If the vectors are in the same direction (the angle between them is 0 degrees), they are more similar.\n",
    "\n",
    "### Computation\n",
    "\n",
    "The cosine similarity between two vectors `a` and `b` is defined as:\n",
    "\n",
    "cosine_similarity(a, b) = dot_product(a, b) / (||a||2 * ||b||2)\n",
    "\n",
    "\n",
    "where `dot_product(a, b)` is the dot product of the vectors `a` and `b`, and `||a||2` and `||b||2` are the Euclidean lengths (L2 norm) of the vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Index\n",
    "\n",
    "The Jaccard Index, also known as the Jaccard similarity coefficient, is a statistic used for comparing the similarity and diversity of sample sets.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "The Jaccard Index measures similarity between finite sample sets and is defined as the size of the intersection divided by the size of the union of the sample sets. It's a measure of how similar the two sets are.\n",
    "\n",
    "### Computation\n",
    "\n",
    "The Jaccard Index between two sets `A` and `B` is defined as:\n",
    "\n",
    "J(A, B) = |A ∩ B| / |A ∪ B|\n",
    "\n",
    "\n",
    "where `|A ∩ B|` is the size of the intersection of `A` and `B`, and `|A ∪ B|` is the size of the union of `A` and `B`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahalanobis Distance\n",
    "\n",
    "The Mahalanobis distance is a measure of the distance between a point and a distribution. It's named after Prasanta Chandra Mahalanobis, an Indian scientist and statistician.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "Unlike Euclidean distance, Mahalanobis distance takes into account the correlations of the data set and is scale-invariant. It measures distance relative to the centroid — a base or reference point that is the mean of all the input points.\n",
    "\n",
    "### Computation\n",
    "\n",
    "The Mahalanobis distance of a multivariate vector `x` from a group of values with mean `μ` and covariance matrix `S` is defined as:\n",
    "\n",
    "D(x) = sqrt((x - μ)T * S^-1 * (x - μ))\n",
    "\n",
    "\n",
    "where `T` denotes the transpose, and `S^-1` is the inverse covariance matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gram-Schmidt Process\n",
    "\n",
    "The Gram-Schmidt process is a method for orthonormalizing a set of vectors in an inner product space, most commonly the Euclidean space R^n. It's named after Jørgen Pedersen Gram and Erhard Schmidt, two mathematicians who independently published this method.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "The Gram-Schmidt process takes a finite, linearly independent set of vectors and generates an orthogonal or orthonormal (if the vectors are normalized) set of vectors that spans the same subspace as the original set.\n",
    "\n",
    "### Computation\n",
    "\n",
    "The Gram-Schmidt process is computed as follows:\n",
    "\n",
    "1. Start with a non-zero vector `v1`, normalize it to get the first vector `u1` in the orthonormal basis.\n",
    "2. For each subsequent vector `vi`, subtract the projection of `vi` onto all the previously computed vectors `u1, ..., ui-1`, and normalize the result to get `ui`.\n",
    "\n",
    "The mathematical formula for the Gram-Schmidt process is:\n",
    "\n",
    "ui = vi - sum((vi * uj) * uj for j = 1 to i-1)\n",
    "\n",
    "\n",
    "where `*` denotes the dot product.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
